{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Este notebook realiza a preparação dos dados e treina um modelo LSTM para prever o valor unitário de um produto.\n",
    "# Ajuste os caminhos dos arquivos conforme necessário.\n",
    "\n",
    "# In[1]:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Configurações de plot\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]:\n",
    "# Caminhos dos arquivos\n",
    "DATA_PATH = '../data'  # Ajuste conforme sua estrutura\n",
    "DATA_FILE = 'dados_transacao_26173.csv' # Ajuste o nome do seu arquivo CSV\n",
    "\n",
    "full_path = os.path.join(DATA_PATH, DATA_FILE)\n",
    "\n",
    "df = pd.read_csv(full_path, sep=',', decimal='.', parse_dates=['Data'], dayfirst=True)\n",
    "\n",
    "# Observando rapidamente o dataframe\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]:\n",
    "# Vamos agrupar por data, obtendo o valor médio diário.\n",
    "# A coluna 'ValorUnitario' existe no dataset original.\n",
    "# Caso a coluna tenha outro nome (ex: ValorUnitario), ajuste abaixo.\n",
    "\n",
    "# Caso o seu CSV tenha o nome da coluna ValorUnitario diferente, ajuste aqui.\n",
    "col_valor = 'ValorUnitario'\n",
    "col_data = 'Data'\n",
    "\n",
    "daily = df.groupby(col_data)[col_valor].mean().to_frame(name='valor_medio_diario')\n",
    "\n",
    "# Converter o índice para datetime, caso ainda não seja\n",
    "daily.index = pd.to_datetime(daily.index)\n",
    "\n",
    "print(daily.head())\n",
    "print(daily.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]:\n",
    "# Vamos criar um índice diário contínuo de 01/01/2019 até 27/08/2024 (ou até o último dia existente no dataset)\n",
    "data_inicial = daily.index.min()\n",
    "data_final = daily.index.max()\n",
    "\n",
    "full_range = pd.date_range(start=data_inicial, end=data_final, freq='D')\n",
    "daily = daily.reindex(full_range)\n",
    "\n",
    "# Preencher valores ausentes com o último valor conhecido\n",
    "daily = daily.ffill()\n",
    "\n",
    "print(daily.isna().sum())\n",
    "print(daily.head())\n",
    "print(daily.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[5]:\n",
    "# Agora vamos separar treino e teste\n",
    "# Treino: 01/01/2019 a 31/12/2023\n",
    "# Teste: 01/01/2024 a 30/03/2024\n",
    "\n",
    "train_end_date = datetime(2023, 12, 31)\n",
    "test_end_date = datetime(2024, 3, 30)\n",
    "\n",
    "train_data = daily.loc[:train_end_date]\n",
    "test_data = daily.loc[datetime(2024,1,1):test_end_date]\n",
    "\n",
    "# Visualização dos dados de treino e teste\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(daily.index, daily['valor_medio_diario'], label='Todos Dados')\n",
    "plt.axvline(x=train_end_date, color='red', linestyle='--', label='Limite Treino/Teste')\n",
    "plt.title('Valor Médio Diário - Histórico')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]:\n",
    "# Normalização dos dados para uso no LSTM\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_data)\n",
    "\n",
    "# Função para criar janelas de tempo (X, y)\n",
    "def create_sequences(data, lookback=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-lookback):\n",
    "        X.append(data[i:i+lookback])\n",
    "        y.append(data[i+lookback])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "lookback = 30\n",
    "X_train, y_train = create_sequences(train_scaled, lookback=lookback)\n",
    "print(\"Shape X_train:\", X_train.shape)\n",
    "print(\"Shape y_train:\", y_train.shape)\n",
    "\n",
    "# Para o teste, precisamos concatenar os últimos 30 dias de 2023 com o teste para termos contexto\n",
    "# Mas como queremos prever a partir de 2024-01-01, precisamos ter os valores anteriores.\n",
    "\n",
    "# Pegar os últimos 30 dias do treino para \"inicializar\" o teste\n",
    "last_days_train = train_data[-lookback:]\n",
    "test_full = pd.concat([last_days_train, test_data], axis=0)\n",
    "test_scaled = scaler.transform(test_full)\n",
    "\n",
    "X_test, y_test = create_sequences(test_scaled, lookback=lookback)\n",
    "\n",
    "# Verificar NaNs\n",
    "print(\"NaNs em X_train:\", np.isnan(X_train).any())\n",
    "print(\"NaNs em y_train:\", np.isnan(y_train).any())\n",
    "print(\"NaNs em X_test:\", np.isnan(X_test).any())\n",
    "print(\"NaNs em y_test:\", np.isnan(y_test).any())\n",
    "\n",
    "print(\"Shape X_test:\", X_test.shape)\n",
    "print(\"Shape y_test:\", y_test.shape)\n",
    "\n",
    "# Note que y_test agora é o valor previsto a partir da primeira data após as 30 janelas finais do treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "# Construindo o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(lookback, 1)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Ajustar o otimizador, por exemplo Adam com taxa de aprendizado menor\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "# Testar função de perda 'mae', pode ser trocada para 'mse' caso desejado\n",
    "model.compile(optimizer=optimizer, loss='mae')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[8]:\n",
    "# Treinamento do modelo\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[9]:\n",
    "# Visualização da curva de loss\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Curva de treinamento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[10]:\n",
    "# Previsões no período de teste\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# O y_test também está em escala transformada, vamos revertê-lo\n",
    "y_test_original = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Ajustar o indice de y_true e y_pred para compararmos\n",
    "test_dates = test_data.index[lookback:]  # datas correspondentes às previsões geradas\n",
    "\n",
    "# Certifique-se que o comprimento de test_dates, y_test_original e y_pred é o mesmo\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "print(\"test_data.shape:\", test_data.shape)\n",
    "\n",
    "test_dates = test_data.index\n",
    "print(\"Len test_dates:\", len(test_dates))\n",
    "print(\"Len y_test_original:\", len(y_test_original))\n",
    "print(\"Len y_pred:\", len(y_pred))\n",
    "\n",
    "# Caso haja discrepância no tamanho, verifique se test_data tem o mesmo número de dias que y_test\n",
    "# Já que criamos as sequências, o y_test terá length = len(test_full) - lookback\n",
    "# E test_full = 30 (lookback) + len(test_data)\n",
    "# Então, len(y_test) = len(test_data)\n",
    "# Logo, devem ser iguais.\n",
    "df_pred = pd.DataFrame({'Data': test_dates, 'Valor Real': y_test_original.flatten(), 'Predição': y_pred.flatten()})\n",
    "\n",
    "df_pred.set_index('Data', inplace=True)\n",
    "\n",
    "print(df_pred.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[11]:\n",
    "# Métricas de avaliação\n",
    "mae = mean_absolute_error(df_pred['Valor Real'], df_pred['Predição'])\n",
    "mse = mean_squared_error(df_pred['Valor Real'], df_pred['Predição'])\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[12]:\n",
    "# Visualização da comparação\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(df_pred.index, df_pred['Valor Real'], label='Valor Real')\n",
    "plt.plot(df_pred.index, df_pred['Predição'], label='Predição')\n",
    "plt.title('Comparação entre Real e Previsto (Teste)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[13]:\n",
    "# Caso queira prever dias futuros (além de 30/03/2024), pode-se fazer a previsão iterativa.\n",
    "# Mas como estamos apenas avaliando o período de teste, já finalizamos aqui.\n",
    "\n",
    "# Observações e melhorias:\n",
    "# - Ajuste do número de épocas, tamanho da janela, arquitetura da rede.\n",
    "# - Testar outros modelos (Prophet, ARIMA, XGBoost) para comparar resultados.\n",
    "# - Ajustar semente random para reprodutibilidade."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
