{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importação das Bibliotecas Necessárias\n",
    "\n",
    "Importamos as bibliotecas essenciais para manipulação de dados, visualização, pré-processamento, construção e treinamento do modelo, e tratamento de feriados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas essenciais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "# Bibliotecas para pré-processamento\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Bibliotecas para construção e treinamento do modelo\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Biblioteca para lidar com feriados\n",
    "import holidays\n",
    "\n",
    "# Ignorar avisos para uma saída mais limpa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Carregamento e Inspeção dos Dados\n",
    "\n",
    "Carregamos o arquivo CSV contendo os dados de vendas e realizamos uma inspeção inicial para entender a estrutura dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o caminho do arquivo CSV\n",
    "csv_path = '../data/dados_transacao_26173.csv'  # Atualize o caminho conforme necessário\n",
    "\n",
    "# Carregar o CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Converter a coluna 'Data' para datetime\n",
    "df['Data'] = pd.to_datetime(df['Data'], format='%Y-%m-%d')\n",
    "\n",
    "# Exibir as primeiras linhas do dataset\n",
    "print(\"Primeiras linhas do dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Informações gerais sobre o dataset\n",
    "print(\"\\nInformações gerais do dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "# Estatísticas descritivas\n",
    "print(\"\\nEstatísticas descritivas:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pré-processamento dos Dados\n",
    "\n",
    "Agregamos os dados por dia, criamos um range completo de datas para garantir que não haja datas faltantes e lidamos com valores ausentes. Também adicionamos lags das vendas anteriores para enriquecer o conjunto de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar os dados por dia\n",
    "daily_df = df.groupby('Data').agg({\n",
    "    'ValorUnitario': 'mean',  # Média do valor unitário por dia\n",
    "    'Quantidade': 'sum'       # Quantidade total vendida por dia\n",
    "}).reset_index()\n",
    "\n",
    "# Exibir as primeiras linhas do dataframe agregado\n",
    "print(\"\\nPrimeiras linhas do dataframe agregado por dia:\")\n",
    "display(daily_df.head())\n",
    "\n",
    "# Criar um range completo de datas\n",
    "all_dates = pd.date_range(start=daily_df['Data'].min(), end=daily_df['Data'].max(), freq='D')\n",
    "daily_df = daily_df.set_index('Data').reindex(all_dates).reset_index()\n",
    "daily_df.rename(columns={'index': 'Data'}, inplace=True)\n",
    "\n",
    "# Preencher valores ausentes\n",
    "daily_df['Quantidade'].fillna(0, inplace=True)\n",
    "daily_df['ValorUnitario'].interpolate(method='linear', inplace=True)\n",
    "daily_df['ValorUnitario'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Confirmar a ausência de valores faltantes\n",
    "print(\"\\nValores faltantes após tratamento:\")\n",
    "print(daily_df.isnull().sum())\n",
    "\n",
    "# Adicionar lags das vendas anteriores\n",
    "for lag in range(1, 8):\n",
    "    daily_df[f'Quantidade_Lag{lag}'] = daily_df['Quantidade'].shift(lag)\n",
    "    daily_df[f'ValorUnitario_Lag{lag}'] = daily_df['ValorUnitario'].shift(lag)\n",
    "\n",
    "# Adicionar lags adicionais até 60 dias\n",
    "for lag in range(8, 60):  # Continuar do lag 8 ao 60\n",
    "    daily_df[f'Quantidade_Lag{lag}'] = daily_df['Quantidade'].shift(lag)\n",
    "    daily_df[f'ValorUnitario_Lag{lag}'] = daily_df['ValorUnitario'].shift(lag)\n",
    "\n",
    "# Preencher valores ausentes resultantes dos lags com zeros\n",
    "daily_df.fillna(0, inplace=True)\n",
    "\n",
    "daily_df['Quantidade'] = np.log1p(daily_df['Quantidade'])  # log1p é log(x+1) para lidar com zeros\n",
    "\n",
    "\n",
    "# Exibir as primeiras linhas com os lags\n",
    "print(\"\\nDataframe com lags adicionados:\")\n",
    "display(daily_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Engenharia de Features\n",
    "\n",
    "Adicionamos features derivadas da data que podem ajudar na previsão, como dia, mês, ano, dia da semana e feriados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar features derivadas da data\n",
    "daily_df['Dia'] = daily_df['Data'].dt.day\n",
    "daily_df['Mes'] = daily_df['Data'].dt.month\n",
    "daily_df['Ano'] = daily_df['Data'].dt.year\n",
    "daily_df['DiaDaSemana'] = daily_df['Data'].dt.dayofweek\n",
    "daily_df['Quantidade_Rolling_Mean'] = daily_df['Quantidade'].rolling(window=7, min_periods=1).mean()\n",
    "daily_df['ValorUnitario_Rolling_Mean'] = daily_df['ValorUnitario'].rolling(window=7, min_periods=1).mean()\n",
    "daily_df['SemanaDoAno'] = daily_df['Data'].dt.isocalendar().week\n",
    "\n",
    "# Inicializar feriados do Brasil\n",
    "br_holidays = holidays.Brazil()\n",
    "\n",
    "# Adicionar coluna de feriado: 1 se feriado, 0 caso contrário\n",
    "daily_df['Feriado'] = daily_df['Data'].isin(br_holidays).astype(int)\n",
    "\n",
    "# Exibir as primeiras linhas com as novas features\n",
    "print(\"\\nDataframe com features adicionais:\")\n",
    "display(daily_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Divisão dos Dados\n",
    "\n",
    "Dividimos os dados em conjuntos de treino inicial, treino continuado/validação e teste conforme a estratégia descrita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as datas de corte\n",
    "train_end = pd.to_datetime('2022-12-31')\n",
    "continue_train_end = pd.to_datetime('2023-12-31')\n",
    "test_start = pd.to_datetime('2024-01-01')\n",
    "test_end = pd.to_datetime('2024-03-30')\n",
    "\n",
    "# Separar os dados\n",
    "train_df = daily_df[daily_df['Data'] <= train_end].reset_index(drop=True)\n",
    "continue_train_df = daily_df[(daily_df['Data'] > train_end) & (daily_df['Data'] <= continue_train_end)].reset_index(drop=True)\n",
    "test_df = daily_df[(daily_df['Data'] >= test_start) & (daily_df['Data'] <= test_end)].reset_index(drop=True)\n",
    "\n",
    "# Exibir o número de registros em cada conjunto\n",
    "print(f\"\\nTreino Inicial: {train_df.shape[0]} registros\")\n",
    "print(f\"Treino Continuado: {continue_train_df.shape[0]} registros\")\n",
    "print(f\"Teste: {test_df.shape[0]} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Escalonamento dos Dados\n",
    "\n",
    "Escalonamos os dados para melhorar o desempenho do modelo LSTM. Utilizamos o MinMaxScaler para normalizar as features e os targets entre 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir features e targets\n",
    "feature_cols = ['Dia', 'Mes', 'Ano', 'DiaDaSemana', 'Feriado', 'SemanaDoAno'] + \\\n",
    "               [f'Quantidade_Lag{lag}' for lag in range(1, 15)] + \\\n",
    "               [f'ValorUnitario_Lag{lag}' for lag in range(1, 15)]\n",
    "\n",
    "target_cols = ['ValorUnitario', 'Quantidade']\n",
    "\n",
    "# Inicializar scalers\n",
    "feature_scaler = MinMaxScaler()\n",
    "target_scaler = MinMaxScaler()\n",
    "\n",
    "# Ajustar scalers nos dados de treino inicial\n",
    "feature_scaler.fit(train_df[feature_cols])\n",
    "target_scaler.fit(train_df[target_cols])\n",
    "\n",
    "# Escalonar dados de treino inicial\n",
    "train_features_scaled = feature_scaler.transform(train_df[feature_cols])\n",
    "train_targets_scaled = target_scaler.transform(train_df[target_cols])\n",
    "\n",
    "# Escalonar dados de treino continuado\n",
    "continue_train_features_scaled = feature_scaler.transform(continue_train_df[feature_cols])\n",
    "continue_train_targets_scaled = target_scaler.transform(continue_train_df[target_cols])\n",
    "\n",
    "# Escalonar dados de teste\n",
    "test_features_scaled = feature_scaler.transform(test_df[feature_cols])\n",
    "test_targets_scaled = target_scaler.transform(test_df[target_cols])\n",
    "\n",
    "# Exibir uma amostra dos dados escalonados de treino\n",
    "print(\"\\nAmostra dos dados escalonados de treino:\")\n",
    "display(pd.DataFrame(train_features_scaled, columns=feature_cols).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Criação de Sequências para o LSTM\n",
    "\n",
    "Criamos sequências temporais dos dados para treinar o modelo LSTM. Cada sequência de entrada consiste em um número fixo de dias anteriores (por exemplo, 30 dias) e a saída é o valor do dia seguinte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar sequências\n",
    "def create_sequences(features, targets, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(seq_length, len(features)):\n",
    "        X.append(features[i-seq_length:i])\n",
    "        y.append(targets[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQ_LENGTH = 60  # Número de dias usados para prever\n",
    "\n",
    "# Criar sequências de treino\n",
    "X_train, y_train = create_sequences(train_features_scaled, train_targets_scaled, SEQ_LENGTH)\n",
    "print(f\"\\nForma de X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "\n",
    "# Criar sequências de treino continuado\n",
    "X_continue_train, y_continue_train = create_sequences(continue_train_features_scaled, continue_train_targets_scaled, SEQ_LENGTH)\n",
    "print(f\"Forma de X_continue_train: {X_continue_train.shape}, y_continue_train: {y_continue_train.shape}\")\n",
    "\n",
    "# Criar sequências de teste\n",
    "X_test, y_test = create_sequences(test_features_scaled, test_targets_scaled, SEQ_LENGTH)\n",
    "print(f\"Forma de X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Construção do Modelo LSTM\n",
    "\n",
    "Definimos a arquitetura do modelo LSTM com camadas adicionais e dropout para melhorar a capacidade de generalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo LSTM avançado com mais camadas\n",
    "\n",
    "# Modelo ajustado com mais camadas e regularização\n",
    "model = Sequential()\n",
    "\n",
    "# Primeira camada LSTM\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(SEQ_LENGTH, len(feature_cols)), \n",
    "               dropout=0.4, recurrent_dropout=0.4, kernel_regularizer=l2(0.01)))\n",
    "# Segunda camada LSTM\n",
    "model.add(LSTM(256, return_sequences=True, dropout=0.4, recurrent_dropout=0.4, kernel_regularizer=l2(0.01)))\n",
    "# Terceira camada LSTM\n",
    "model.add(LSTM(128, return_sequences=False, dropout=0.4, recurrent_dropout=0.4, kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Camadas densas para processar as saídas da LSTM\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Camada de saída\n",
    "model.add(Dense(len(target_cols)))\n",
    "\n",
    "# Compilação do modelo com taxa de aprendizado reduzida\n",
    "optimizer = Adam(learning_rate=0.0005)  # Taxa de aprendizado inicial ajustada\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Exibir o resumo do modelo\n",
    "print(\"\\nResumo do modelo LSTM avançado:\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Treinamento do Modelo\n",
    "\n",
    "Treinamos o modelo inicialmente com os dados de treino (até 31/12/2022) e depois continuamos o treinamento com os dados de 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=80, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "\n",
    "# Criar múltiplas janelas para comparação\n",
    "for seq_length in [30, 60, 90]:\n",
    "    X_train, y_train = create_sequences(train_features_scaled, train_targets_scaled, seq_length)\n",
    "    print(f\"Treinamento com janela de {seq_length} dias: X_train.shape = {X_train.shape}\")\n",
    "\n",
    "# Treinar o modelo com os dados de treino inicial\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,  # Mantendo 200 épocas para garantir tempo suficiente de treinamento\n",
    "    batch_size=64,  # Lote ajustado para balancear memória e desempenho\n",
    "    validation_split=0.1,  # Separar 10% dos dados de treino para validação\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1  # Mostrar logs detalhados\n",
    ")\n",
    "\n",
    "# Plotar a perda de treino e validação\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['loss'], label='Treino')\n",
    "plt.plot(history.history['val_loss'], label='Validação')\n",
    "plt.title('Perda do Modelo durante o Treinamento Inicial')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento contínuo para ajustar novas tendências de 2023\n",
    "history_continue = model.fit(\n",
    "    X_continue_train, y_continue_train,\n",
    "    epochs=200,  # Período de ajuste mais curto\n",
    "    batch_size=64,  # Mantendo o mesmo batch size\n",
    "    validation_split=0.1,  # Validação consistente com o treinamento inicial\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plotar a perda de treino e validação durante a continuação do treinamento\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history_continue.history['loss'], label='Treino Continuado')\n",
    "plt.plot(history_continue.history['val_loss'], label='Validação Continuada')\n",
    "plt.title('Perda do Modelo durante a Continuação do Treinamento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da Perda durante o Treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a perda de treino e validação\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['loss'], label='Treino')\n",
    "plt.plot(history.history['val_loss'], label='Validação')\n",
    "plt.title('Perda do Modelo durante o Treinamento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Previsão e Avaliação do Modelo\n",
    "\n",
    "Realizamos previsões para o conjunto de teste, invertemos o escalonamento dos dados e avaliamos o desempenho do modelo utilizando métricas como MSE e MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar o número de registros em test_df\n",
    "print(f\"Número de registros em test_df: {len(test_df)}\")\n",
    "print(f\"Tamanho da sequência (SEQ_LENGTH): {SEQ_LENGTH}\")\n",
    "\n",
    "# Garantir que test_df tenha registros suficientes\n",
    "if len(test_df) < SEQ_LENGTH:\n",
    "    missing_records = SEQ_LENGTH - len(test_df)\n",
    "    print(f\"Expandindo test_df com {missing_records} registros do treino contínuo.\")\n",
    "    test_df = pd.concat([continue_train_df.tail(missing_records), test_df]).reset_index(drop=True)\n",
    "    continue_train_df = continue_train_df.iloc[:-missing_records].reset_index(drop=True)\n",
    "\n",
    "# Recriar sequências de teste\n",
    "X_test, y_test = create_sequences(test_features_scaled, test_targets_scaled, SEQ_LENGTH)\n",
    "print(f\"Forma de X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# Realizar previsões somente se X_test não estiver vazio\n",
    "if X_test.shape[0] > 0:\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Inverter o escalonamento das previsões e dos valores reais\n",
    "    predictions_inverse = target_scaler.inverse_transform(predictions)\n",
    "    y_test_inverse = target_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # Garantir valores não negativos após inversão\n",
    "    predictions_inverse = np.clip(predictions_inverse, a_min=0, a_max=None)\n",
    "    y_test_inverse = np.clip(y_test_inverse, a_min=0, a_max=None)\n",
    "\n",
    "    # Criar DataFrame para comparação\n",
    "    comparison_df = test_df.iloc[SEQ_LENGTH:].copy().reset_index(drop=True)\n",
    "    comparison_df['ValorUnitario_Previsto'] = predictions_inverse[:, 0]\n",
    "    comparison_df['Quantidade_Prevista'] = predictions_inverse[:, 1]\n",
    "\n",
    "    # Calcular métricas\n",
    "    mse_valor = mean_squared_error(y_test_inverse[:, 0], predictions_inverse[:, 0])\n",
    "    mae_valor = mean_absolute_error(y_test_inverse[:, 0], predictions_inverse[:, 0])\n",
    "    mse_quant = mean_squared_error(y_test_inverse[:, 1], predictions_inverse[:, 1])\n",
    "    mae_quant = mean_absolute_error(y_test_inverse[:, 1], predictions_inverse[:, 1])\n",
    "    r2_valor = r2_score(y_test_inverse[:, 0], predictions_inverse[:, 0])\n",
    "    r2_quant = r2_score(y_test_inverse[:, 1], predictions_inverse[:, 1])\n",
    "\n",
    "    # Exibir métricas\n",
    "    print(f\"Valor Unitário - R²: {r2_valor:.4f}, MSE: {mse_valor:.4f}, MAE: {mae_valor:.4f}\")\n",
    "    print(f\"Quantidade Vendida - R²: {r2_quant:.4f}, MSE: {mse_quant:.4f}, MAE: {mae_quant:.4f}\")\n",
    "else:\n",
    "    print(\"Erro: X_test ainda está vazio. Verifique os dados de entrada e o SEQ_LENGTH.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Visualização dos Resultados\n",
    "\n",
    "Visualizamos as previsões comparadas com os valores reais para entender o desempenho do modelo ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotagem - Real vs Previsto\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "# Valor Unitário\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(comparison_df['Data'], comparison_df['ValorUnitario'], label='Real', color='blue')\n",
    "plt.plot(comparison_df['Data'], comparison_df['ValorUnitario_Previsto'], label='Previsto', color='orange', linestyle='dashed')\n",
    "plt.title('Valor Unitário - Real vs Previsto')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Valor Unitário')\n",
    "plt.legend()\n",
    "\n",
    "# Quantidade Vendida\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(comparison_df['Data'], comparison_df['Quantidade'], label='Real', color='green')\n",
    "plt.plot(comparison_df['Data'], comparison_df['Quantidade_Prevista'], label='Previsto', color='red', linestyle='dashed')\n",
    "plt.title('Quantidade Vendida - Real vs Previsto')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Quantidade Vendida')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Conclusão\n",
    "\n",
    "Com base nas métricas e visualizações, podemos avaliar a precisão do modelo e identificar áreas para melhorias futuras."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
